from bs4 import BeautifulSoup
import requests
import pandas as pd

url = 'https://kinogo.film/'
response = requests.get(url)
soup = BeautifulSoup(response.text, "lxml")

films = soup.findAll('div', class_='shortstory')
data = []
for film in films:
    link = film.find('h2', class_='zagolovki').find('a').get('href')
    name_of_film = film.find('h2', class_='zagolovki').find('a').text
    data.append([link, name_of_film])

print(data)

header = ['link', 'name_of_film']
df = pd.DataFrame(data, columns=header)
df.to_csv('C:/Users/AZAMAT/Desktop/kinogo.csv', sep=';', encoding='utf8')





//eshe



from bs4 import BeautifulSoup
import requests
import os
import sqlite3
import queries


# try:
#     os.remove("C:/Users/AZAMAT/Desktop/data.xlsx")
# except Exception as ex:
#     print(ex)

url = 'https://www.nur.kz/society/'
response = requests.get(url)
soup = BeautifulSoup(response.text, "lxml")

films = soup.findAll('article', class_='block-infinite__item-content')
data = []
for film in films:
    link = film.find('a').get('href')
    title = film.find('h3').text.strip()
    datetime = film.find('time').text.strip()
    data.append([link, title, datetime])


# try:
#     conn = sqlite3.connect('db.db')
#     conn.execute('''drop table news;''')
#     conn.execute('''create table news
#                         (id int primary key not null,
#                         link text not null ,
#                         title text not null ,
#                         datetime date not null
#                         );
#                         ''')
#     conn.close()
# except Exception as ex:
#     print(ex)

# try:
#     connection = sqlite3.connect('db.db')
#     cursor = connection.cursor()
#     query = '''INSERT INTO news (link, title, datetime) VALUES (?, ?, ?)'''
#     values = data
#     cursor.executemany(query, values)
#     connection.commit()
#     connection.close()
#     print("success")
# except Exception as ex:
#     print(ex)



///////////////
from bs4 import BeautifulSoup
import requests
import queries
import datetime
import dateparser


# url = 'https://www.nur.kz/society/'
# response = requests.get(url)
# soup = BeautifulSoup(response.text, "lxml")
# films = soup.findAll('article', class_='block-infinite__item-content')
# data = []


def parse(url, response, soup, films, data):
    for film in films:
        link = film.find('a').get('href')  # это поле содержит ссылку на новость
        title = film.find('h3').text.strip()  # это поле содержит заголовок новости.
        datetime_from_website = film.find('time').text.strip()
        timestamp = dateparser.parse(datetime_from_website)
        nd_date = datetime.datetime.timestamp(
            timestamp) * 1000  # это поле содержит дату и время новости в формате Unix time
        current_time = datetime.datetime.now()
        s_date = datetime.datetime.timestamp(
            current_time) * 1000  # это поле содержит дату и время попадания новости в саму таблицу items в формате Unix time
        not_date = timestamp.strftime("%Y-%m-%d")  # это поле содержит дату новости в формате Год-Месяц-День
        data.append([link, title, nd_date, s_date, not_date])




# for film in films:
#     link = film.find('a').get('href')                           # это поле содержит ссылку на новость
#     title = film.find('h3').text.strip()                        # это поле содержит заголовок новости.
#     datetime_from_website = film.find('time').text.strip()
#     timestamp = dateparser.parse(datetime_from_website)
#     nd_date = datetime.datetime.timestamp(timestamp) * 1000     # это поле содержит дату и время новости в формате Unix time
#     current_time = datetime.datetime.now()
#     s_date = datetime.datetime.timestamp(current_time) * 1000   #  это поле содержит дату и время попадания новости в саму таблицу items в формате Unix time
#     not_date = timestamp.strftime("%Y-%m-%d")                   # это поле содержит дату новости в формате Год-Месяц-День
#     data.append([link, title, nd_date, s_date, not_date])


# queries.drop_table_items()
# queries.create_table_items()
# queries.insert_to_items(data)

queries.drop_table_resource()
queries.create_table_resource()

