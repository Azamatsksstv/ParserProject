from bs4 import BeautifulSoup
import requests
import pandas as pd

url = 'https://kinogo.film/'
response = requests.get(url)
soup = BeautifulSoup(response.text, "lxml")

films = soup.findAll('div', class_='shortstory')
data = []
for film in films:
    link = film.find('h2', class_='zagolovki').find('a').get('href')
    name_of_film = film.find('h2', class_='zagolovki').find('a').text
    data.append([link, name_of_film])

print(data)

header = ['link', 'name_of_film']
df = pd.DataFrame(data, columns=header)
df.to_csv('C:/Users/AZAMAT/Desktop/kinogo.csv', sep=';', encoding='utf8')





//eshe



from bs4 import BeautifulSoup
import requests
import os
import sqlite3
import queries


# try:
#     os.remove("C:/Users/AZAMAT/Desktop/data.xlsx")
# except Exception as ex:
#     print(ex)

url = 'https://www.nur.kz/society/'
response = requests.get(url)
soup = BeautifulSoup(response.text, "lxml")

films = soup.findAll('article', class_='block-infinite__item-content')
data = []
for film in films:
    link = film.find('a').get('href')
    title = film.find('h3').text.strip()
    datetime = film.find('time').text.strip()
    data.append([link, title, datetime])


# try:
#     conn = sqlite3.connect('db.db')
#     conn.execute('''drop table news;''')
#     conn.execute('''create table news
#                         (id int primary key not null,
#                         link text not null ,
#                         title text not null ,
#                         datetime date not null
#                         );
#                         ''')
#     conn.close()
# except Exception as ex:
#     print(ex)

# try:
#     connection = sqlite3.connect('db.db')
#     cursor = connection.cursor()
#     query = '''INSERT INTO news (link, title, datetime) VALUES (?, ?, ?)'''
#     values = data
#     cursor.executemany(query, values)
#     connection.commit()
#     connection.close()
#     print("success")
# except Exception as ex:
#     print(ex)


